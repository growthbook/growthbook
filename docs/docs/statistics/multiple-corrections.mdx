---
title: Multiple Testing Corrections
description: Multiple Testing Corrections
sidebar_label: Multiple Testing Corrections
slug: multiple-corrections
---

# Multiple Testing Corrections

:::note

Multiple Testing Corrections are only implemented for the Frequentist statistics engine.

:::

If you test a bunch of things at once, you will naturally get some results that look good, but aren't real! This page explains this problem in detail and how you can control it with GrowthBook.

### What is the multiple testing problem?

In the frequentist framework, testing more than one hypothesis at a time increases the probability that you find a false positive, beyond the user's specified rate of $\alpha$, often 0.05. This is often known as the [multiple testing](https://en.wikipedia.org/wiki/Multiple_comparisons_problem), or multiple comparisons, problem.

In online AB testing, experimenters will often be running hundreds of tests, if not tens of thousands, of tests, at the same time. In this setting, a "test" tends to be the comparison of variation A vs variation B, for one group, for one metric. If you are running 10 experiments with 2 variations, each with 10 metrics, you are running 100 tests at one time. Even if the test had no effect on any metric, having this many tests will dramatically increase the chance of seeing a false positive.

### Error rates

To understand approaches to solving this issue, let's first define two the False Discovery Rate and the Family Wise Error Rate:

$$\text{False Discovery Rate} = \text{FDR} = \text{E}[\frac{V}{V+R}]$$

$$\text{Family-wise Error Rate} = \text{FWER} = \text{Pr}(V \geq 1)$$

where $V$ is the number of tests that are statistically significant but are false positives and $R$ are the number of tests that are statistically signficant.

In plain English, the FDR is proportion of your significant results that are false. If you control your FDR at 0.05 (or 5%), and you get 20 significant results, on average only 1 of these should be a false positive.

The FWER is the probability of at least one test being a false positive. This tends to be much stricter as the number of tests grows.

## Corrections in GrowthBook

### Statistical methods

Growthbook allows you to choose no multiple testing correction, a correction that controls your False Discovery Rate (Benjamini-Hochberg), and a correction that controls your Family-wise Error Rate (Holm-Bonferroni).

You can set this for your organization in the Organization -> Settings page, as seen below:

TODO SCREENSHOT

Which you choose depends on your tolerance for false positives, the number of tests you are running, and your comfort with each procedure. General guidance would be that if your analysis is more exploratory, controlling the FDR and having a slightly higher false positive rate may be better, while controlling the FWER will give you more guarantees that your results are reliable. However, with enough tests, controlling the FWER may completely undermine your test power.

#### Holm-Bonferroni (controlling FWER)

To control the FWER, we implement the [Holm-Bonferroni method](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method). This method is an adaptation of the well known Bonferroni method, which simply multiplies p-values by the number of tests in the family.

The Holm-Bonferroni does just as well as the Bonferroni method to control the FWER, but it also has more power (e.g. it is less conservative). The main trade-off is that the implementation is slightly more complex, and one cannot adjust the confidence intervals in a meaningful way.

There are other approaches that will be even less conservative, but they require making assumptions about the dependence between tests.

#### Benjamini-Hochberg (controlling FDR)

To control the FDR< we implement the [Benjamini-Hochberg procedure](https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini%E2%80%93Hochberg_procedure). While the Holm-Bonferroni method made no additional assumptions to controlling the FWER, this method does assume that the tests are independent or postively correlated. There are methods that make fewer assumptions (such as the Benjamini-Yekutieli method), but they can be even more conservative than Bonferroni corrections.

Therefore, in order to provide a reasonably powered approach that controls the FDR in some conditions, and to select an approach that has widespread adoption, we implemented the Benjamini-Hochberg procedure.

### Defining a family of tests

GrowthBook allows experimenters to run a wide variety of analyses at regular intervals and on an ad-hoc basis. Controlling for multiple comparisons across all of these tests, even within the context of one experiment, is impractical and costly, in terms of statistical power.

As such, GrowthBook defines the following family of tests and applies your chosen correction within them:

On the _experiment results overall page_, we collect all tests across non-guardrail metrics and variations to be part of a family, and correct within those values. The following image circles the p-values that we collect and adjust for on the overall results page for an experiment.

TODO SCREENSHOT

If you look within dimensional slices, to account for the additional increase in tests from dimensional splits, we collect all tests across all dimensions, all non-guardrail metrics, and all variations and correc within that family. The following image circles the p-values we collect and adjust for on a dimension split page.

TODO SCREENSHOT

This means that we never correct across overall _and_ dimension splits at the same time.
