# Testing GrowthBooks SQL Integration for Experiments

This folder contains scripts used to automatically lint and run SQL generated by the `getExperimentMetricQuery()` method that all of our SQL integrations use to generate metric values for the Python stats library `gbstats`. Testing these queries is difficult because there are (a) many SQL languages that have their own rules and often require their own DBs and (b) they are somewhat modular in how they are built, but unit testing each step is almost more complicated to set up.

Therefore, this folder contains scripts to generate experiment metric queries for a wide range of engines and experiment-metric configurations and then execute them against a variety of DBs. The output can then be compared using a Jupyter notebook, akin to the one here.

## How to use it

If you satisfy the (hefty) pre-requisites below, you can simply run the following once in the main git branch and whatever branch you wish to test:
`yarn workspace back-end test-integration-queries`

Once that script runs, you can use a [notebook like this one](https://colab.research.google.com/drive/1J-VBFGQ2a_7cyarrNRPXuHlQXVfB55yy?usp=sharing) to compare two sets of results across the main and dev branch from which you ran the above script.

The `test-integration-queries` command runs `integration-query-test.sh` which itself:

1. Generates the queries using `integration-query-generator.ts`
2. Gets the current git branch
3. Lints and executes the queries, storing results using the current git branch as part of the file name, using `integration-query-runner.py`

### Caching

Note a shared cache in your `/tmp/` folder is used for each run. If the combination of SQL engine and SQL query itself is identical, the results should be pulled directly from the cache rather than re-generated.

We even cache connection/query errors to avoid re-running validation for engines that we cannot connect to. You may need to clear part of the cache file or edit one of the if statements in the `main()` method of the python script to force re-running for certain engines if they previously errored and you want them to connect and execute.

### Pre-requisites

You will need:

1. To set up local/cloud (for now) MySQL, Postgres, Presto DBs and have BigQuery and Snowflake instances with data loaded from the back-end data generator (see the back-end README for instructions on how to create and load this data).
2. A `.env` file that lives in this folder that looks like the following, replacing XXX with the appropriate values for the databases you set up in step 1:

```
export MYSQL_TEST_HOST=XXX
export MYSQL_TEST_USER=XXX
export MYSQL_TEST_DATABASE=XXX
export MYSQL_TEST_PASSWORD=XXX

export POSTGRES_TEST_HOST=XXX
export POSTGRES_TEST_USER=XXX
export POSTGRES_TEST_DATABASE=XXX

export SNOWFLAKE_TEST_ACCOUNT=XXX
export SNOWFLAKE_TEST_DATABASE=XXX
export SNOWFLAKE_TEST_SCHEMA=XXX
export SNOWFLAKE_TEST_USER=XXX
export SNOWFLAKE_TEST_PASSWORD=XXX

export PRESTO_TEST_HOST=XXX
export PRESTO_TEST_PORT=XXX
export PRESTO_TEST_USER=XXX
export PRESTO_TEST_CATALOG=XXX
export PRESTO_TEST_SCHEMA=XXX

export DATABRICKS_TEST_HOST=XXX
export DATABRICKS_TEST_PATH=XXX
export DATABRICKS_TEST_TOKEN=XXX


export GOOGLE_APPLICATION_CREDENTIALS="XXX.json"
```

3. The requisite python connectors in `integration-query-runner.py` installed on your machine. These are specified in this folder's pyproject.tomlm file. You can install these by changing to this directory and running `poetry update`.

## Other notes

If contributing to this python script, please consider linting with `black` and `flake8`.

GrowthBook team members can read more documentation and which integrations/configurations are covered in this doc: https://www.notion.so/growthbook/Testing-Stats-Integrations-4e549c1591de444ea0f19473d3257f7d#24e7d771aece432f9aeeaad9e8aabfa7
