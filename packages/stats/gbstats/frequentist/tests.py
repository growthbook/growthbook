from abc import abstractmethod
from dataclasses import asdict
from typing import Optional, List

import numpy as np
from pydantic.dataclasses import dataclass
from scipy.stats import t
from gbstats.messages import (
    ZERO_SCALED_VARIATION_MESSAGE,
    NO_UNITS_IN_VARIATION_MESSAGE,
)
from gbstats.models.tests import (
    EffectMomentsResult,
    TestResult,
    Uplift,
    BaseConfig,
)

from typing import Literal


# Configs
@dataclass
class FrequentistConfig(BaseConfig):
    test_value: float = 0


@dataclass
class SequentialConfig(FrequentistConfig):
    sequential_tuning_parameter: float = 5000


PValueErrorMessage = Literal[
    "NUMERICAL_PVALUE_NOT_CONVERGED",
    "ALPHA_GREATER_THAN_0.5_FOR_SEQUENTIAL_ONE_SIDED_TEST",
]


# Results
@dataclass
class FrequentistTestResult(TestResult):
    unadjusted_baseline_mean: float
    n: int
    p_value: Optional[float] = None
    p_value_error_message: Optional[PValueErrorMessage] = None


@dataclass
class PValueResult:
    p_value: Optional[float | None] = None
    p_value_error_message: Optional[PValueErrorMessage] = None


# Tests


class TTest:
    def __init__(
        self,
        result: EffectMomentsResult,
        config: FrequentistConfig = FrequentistConfig(),
    ):
        """Base class for one- and two-sided T-Tests with unequal variance.
        All values are with respect to relative effects, not absolute effects.
        A result prepared for integration with the stats runner can be
        generated by calling `.compute_result()`

        Args:
            result (EffectMomentsResult): the result of the EffectMoments class
        """
        self.result = result
        self.n = result.stat_a.n + result.stat_b.n
        self.point_estimate = result.point_estimate
        self.standard_error = result.standard_error
        self.dof = result.degrees_of_freedom
        self.unadjusted_baseline_mean = result.unadjusted_baseline_mean
        self.scaled_impact_eligible = result.scaled_impact_eligible
        self.moments_error_message = result.error_message
        self.alpha = config.alpha
        self.test_value = config.test_value
        self.relative = config.difference_type == "relative"
        self.scaled = config.difference_type == "scaled"
        self.traffic_percentage = config.traffic_percentage
        self.total_users = config.total_users
        self.phase_length_days = config.phase_length_days

    @property
    def critical_value(self) -> float:
        return (self.point_estimate - self.test_value) / self.standard_error

    @property
    @abstractmethod
    def p_value(self) -> float | None:
        pass

    @property
    @abstractmethod
    def confidence_interval(self) -> List[float]:
        pass

    def _default_output(
        self,
        error_message: Optional[str] = None,
        p_value_error_message: Optional[PValueErrorMessage] = None,
    ) -> FrequentistTestResult:
        """Return uninformative output when AB test analysis can't be performed
        adequately
        """
        return FrequentistTestResult(
            expected=0,
            ci=[0, 0],
            p_value=1,
            uplift=Uplift(
                dist="normal",
                mean=0,
                stddev=0,
            ),
            error_message=error_message,
            p_value_error_message=p_value_error_message,
            unadjusted_baseline_mean=self.unadjusted_baseline_mean,
            n=self.n,
        )

    def compute_p_value(self) -> PValueResult:
        return PValueResult(
            p_value=self.p_value,
            p_value_error_message=None,
        )

    @property
    def sequential_one_sided_test(self) -> bool:
        return False

    def compute_result(self) -> FrequentistTestResult:
        """Compute the test statistics and return them
        for the main gbstats runner

        Returns:
            FrequentistTestResult -
                note the values are with respect to percent uplift,
                not absolute differences
        """
        if self.moments_error_message:
            return self._default_output(error_message=self.moments_error_message)

        if self.sequential_one_sided_test and self.alpha >= 0.5:
            return self._default_output(
                error_message=None,
                p_value_error_message="ALPHA_GREATER_THAN_0.5_FOR_SEQUENTIAL_ONE_SIDED_TEST",
            )

        p_value_result = self.compute_p_value()

        result = FrequentistTestResult(
            expected=self.point_estimate,
            ci=self.confidence_interval,
            p_value=p_value_result.p_value,
            uplift=Uplift(
                dist="normal",
                mean=self.point_estimate,
                stddev=self.standard_error,
            ),
            error_message=None,
            p_value_error_message=p_value_result.p_value_error_message,
            unadjusted_baseline_mean=self.unadjusted_baseline_mean,
            n=self.n,
        )
        if self.scaled:
            result = self.scale_result(result)
        return result

    def scale_result(self, result: FrequentistTestResult) -> FrequentistTestResult:
        if self.phase_length_days == 0 or self.traffic_percentage == 0:
            return self._default_output(ZERO_SCALED_VARIATION_MESSAGE)
        if self.scaled_impact_eligible:
            if self.total_users:
                adjustment = self.total_users / (
                    self.traffic_percentage * self.phase_length_days
                )
                return FrequentistTestResult(
                    expected=result.expected * adjustment,
                    ci=[result.ci[0] * adjustment, result.ci[1] * adjustment],
                    p_value=result.p_value,
                    uplift=Uplift(
                        dist=result.uplift.dist,
                        mean=result.uplift.mean * adjustment,
                        stddev=result.uplift.stddev * adjustment,
                    ),
                    error_message=None,
                    p_value_error_message=result.p_value_error_message,
                    unadjusted_baseline_mean=result.unadjusted_baseline_mean,
                    n=result.n,
                )
            else:
                return self._default_output(NO_UNITS_IN_VARIATION_MESSAGE)
        else:
            error_str = "For scaled impact the statistic must be of type ProportionStatistic, SampleMeanStatistic, or RegressionAdjustedStatistic."
            return self._default_output(error_str)


def one_sided_confidence_interval(
    point_estimate: float, halfwidth: float, lesser: bool = True
) -> List[float]:
    if lesser:
        return [-np.inf, point_estimate + halfwidth]
    else:
        return [point_estimate - halfwidth, np.inf]


def two_sided_confidence_interval(
    point_estimate: float, halfwidth: float
) -> List[float]:
    return [point_estimate - halfwidth, point_estimate + halfwidth]


class TwoSidedTTest(TTest):
    @property
    def p_value(self) -> float:
        return 2 * (1 - t.cdf(abs(self.critical_value), self.dof))  # type: ignore

    @property
    def confidence_interval(self) -> List[float]:
        halfwidth: float = float(
            t.ppf(1 - self.alpha / 2, self.dof) * self.standard_error
        )
        return two_sided_confidence_interval(self.point_estimate, halfwidth)


class OneSidedTreatmentGreaterTTest(TTest):
    @property
    def p_value(self) -> float:
        return 1 - t.cdf(self.critical_value, self.dof)  # type: ignore

    @property
    def confidence_interval(self) -> List[float]:
        halfwidth: float = float(t.ppf(1 - self.alpha, self.dof) * self.standard_error)
        return one_sided_confidence_interval(
            self.point_estimate, halfwidth, lesser=False
        )


class OneSidedTreatmentLesserTTest(TTest):
    @property
    def p_value(self) -> float:
        return t.cdf(self.critical_value, self.dof)  # type: ignore

    @property
    def confidence_interval(self) -> List[float]:
        halfwidth: float = float(t.ppf(1 - self.alpha, self.dof) * self.standard_error)
        return one_sided_confidence_interval(
            self.point_estimate, halfwidth, lesser=True
        )


def sequential_rho(alpha, sequential_tuning_parameter, two_sided=True) -> float:
    # eq 161 in https://arxiv.org/pdf/2103.06476v7.pdf
    alpha_arg = alpha if two_sided else 2 * alpha
    return np.sqrt(
        (-2 * np.log(alpha_arg) + np.log(-2 * np.log(alpha_arg) + 1))
        / sequential_tuning_parameter
    )


def sequential_interval_halfwidth(s2, n, sequential_tuning_parameter, alpha) -> float:
    rho = sequential_rho(alpha, sequential_tuning_parameter, two_sided=True)
    # eq 9 in Waudby-Smith et al. 2023 https://arxiv.org/pdf/2103.06476v7.pdf
    return np.sqrt(s2) * np.sqrt(
        (
            (2 * (n * np.power(rho, 2) + 1))
            * np.log(np.sqrt(n * np.power(rho, 2) + 1) / alpha)
            / (np.power(n * rho, 2))
        )
    )


def sequential_interval_halfwidth_one_sided(
    s2, n, sequential_tuning_parameter, alpha
) -> float:
    rho = sequential_rho(alpha, sequential_tuning_parameter, two_sided=False)
    # eq 134 in https://arxiv.org/pdf/2103.06476v7.pdf
    part_1 = s2
    part_2 = 2 * (n * np.power(rho, 2) + 1) / (np.power(n * rho, 2))
    part_3 = np.log(1 + np.sqrt(n * np.power(rho, 2) + 1) / (2 * alpha))
    return np.sqrt(part_1 * part_2 * part_3)


class SequentialTTest(TTest):
    def __init__(
        self,
        result: EffectMomentsResult,
        config: SequentialConfig = SequentialConfig(),
    ):
        config_dict = asdict(config)
        self.sequential_tuning_parameter = config_dict.pop(
            "sequential_tuning_parameter"
        )
        super().__init__(result, FrequentistConfig(**config_dict))

    @property
    def rho(self) -> float:
        # eq 161 in https://arxiv.org/pdf/2103.06476v7.pdf
        return sequential_rho(
            self.alpha, self.sequential_tuning_parameter, two_sided=True
        )

    @property
    @abstractmethod
    def halfwidth(self) -> float:
        pass

    # "variance" of the treatment effect distribution;
    @property
    def s2(self) -> float:
        return self.standard_error**2 * self.n


class SequentialTwoSidedTTest(SequentialTTest):
    @property
    def halfwidth(self) -> float:
        return sequential_interval_halfwidth(
            self.s2, self.n, self.sequential_tuning_parameter, self.alpha
        )

    @property
    def confidence_interval(self) -> List[float]:
        return two_sided_confidence_interval(self.point_estimate, self.halfwidth)

    @property
    def p_value(self) -> float:
        # eq 155 in https://arxiv.org/pdf/2103.06476v7.pdf
        # slight reparameterization for this quantity below
        st2 = (
            np.power(self.point_estimate - self.test_value, 2)
            * self.n
            / (self.standard_error**2)
        )
        tr2p1 = self.n * np.power(self.rho, 2) + 1
        evalue = np.exp(np.power(self.rho, 2) * st2 / (2 * tr2p1)) / np.sqrt(tr2p1)
        return min(1 / evalue, 1)


class SequentialOneSidedTreatmentLesserTTest(SequentialTTest):
    @property
    def sequential_one_sided_test(self) -> bool:
        return True

    @property
    def lesser(self) -> bool:
        return True

    @property
    def halfwidth(self) -> float:
        return sequential_interval_halfwidth_one_sided(
            self.s2,
            self.n,
            self.sequential_tuning_parameter,
            self.alpha,
        )

    @property
    def confidence_interval(self) -> List[float]:
        return one_sided_confidence_interval(
            self.point_estimate, self.halfwidth, lesser=self.lesser
        )

    @property
    def p_value(self) -> float | None:
        return None

    def compute_p_value(self) -> PValueResult:
        difference_type = (
            "relative" if self.relative else "scaled" if self.scaled else "absolute"
        )
        tol = 1e-6
        max_iters = 100
        min_alpha = 1e-5
        max_alpha = 0.4999
        this_config = SequentialConfig(difference_type=difference_type, alpha=min_alpha)
        this_test = (
            SequentialOneSidedTreatmentLesserTTest
            if self.lesser
            else SequentialOneSidedTreatmentGreaterTTest
        )
        ci_index = 1 if self.lesser else 0
        this_ci_small = this_test(self.result, this_config).confidence_interval
        # smaller alpha => bigger confidence interval;
        if self.lesser:
            if this_ci_small[ci_index] < 0:
                return PValueResult(
                    p_value=min_alpha,
                    p_value_error_message=None,
                )
            this_config.alpha = max_alpha
            # bigger alpha => smaller confidence interval;
            this_ci_big = this_test(self.result, this_config).confidence_interval
            if this_ci_big[ci_index] > 0:
                return PValueResult(
                    p_value=max_alpha,
                    p_value_error_message=None,
                )
        else:
            if this_ci_small[ci_index] > 0:
                return PValueResult(
                    p_value=min_alpha,
                    p_value_error_message=None,
                )
            this_config.alpha = max_alpha
            # bigger alpha => smaller confidence interval;
            this_ci_big = this_test(self.result, this_config).confidence_interval
            if this_ci_big[ci_index] < 0:
                return PValueResult(
                    p_value=max_alpha,
                    p_value_error_message=None,
                )
        iters = 0
        this_alpha = 0.5 * (min_alpha + max_alpha)
        diff = 0
        for _ in range(max_iters):
            this_config.alpha = this_alpha
            this_ci = this_test(self.result, this_config).confidence_interval
            diff = this_ci[ci_index] - 0
            if self.lesser:
                if diff > 0:
                    min_alpha = this_alpha
                else:
                    max_alpha = this_alpha
            else:
                if diff < 0:
                    min_alpha = this_alpha
                else:
                    max_alpha = this_alpha
            this_alpha = 0.5 * (min_alpha + max_alpha)
            if abs(diff) < tol:
                break
        converged = abs(diff) < tol and iters != max_iters
        if converged:
            return PValueResult(
                p_value=this_alpha,
                p_value_error_message=None,
            )
        else:
            return PValueResult(
                p_value=None,
                p_value_error_message="NUMERICAL_PVALUE_NOT_CONVERGED",
            )


class SequentialOneSidedTreatmentGreaterTTest(SequentialOneSidedTreatmentLesserTTest):
    @property
    def lesser(self) -> bool:
        return False
